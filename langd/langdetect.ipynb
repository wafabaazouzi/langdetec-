{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "data = pd.read_csv(r\"C:\\Users\\wafa\\Desktop\\stage\\wafa.csv\", encoding ='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=\"sentID.BTEC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  lang                                  sent\n",
      "0  ALE  هو هنيك، قدام معلومات السياح بالضبط.\n",
      "1  ALE      مالي سمعان من قبل بهالعنوان هون.\n",
      "2  ALE         روح ساوي لبين ما تشوف صيدلية.\n",
      "3  ALE                          بشقد الفطور؟\n",
      "4  ALE                     شلون بقدر أساعدك؟\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(columns=\"split\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100024, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang    0\n",
       "sent    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAI     12000\n",
       "RAB     12000\n",
       "BEI     12000\n",
       "TUN     12000\n",
       "DOH     12000\n",
       "SAN      2000\n",
       "ALE      2000\n",
       "SAL      2000\n",
       "ASW      2000\n",
       "JED      2000\n",
       "MOS      2000\n",
       "RIY      2000\n",
       "BAS      2000\n",
       "SFX      2000\n",
       "MUS      2000\n",
       "ALX      2000\n",
       "DAM      2000\n",
       "TRI      2000\n",
       "AMM      2000\n",
       "KHA      2000\n",
       "ALG      2000\n",
       "BAG      2000\n",
       "JER      2000\n",
       "FES      2000\n",
       "BEN      2000\n",
       "lang       24\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =np.array(data[\"sent\"])\n",
    "y =np.array(data[\"lang\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ebc735bcc515>:7: FutureWarning: Possible nested set at position 1\n",
      "  sent = re.sub(r'[[]]', ' ', sent)\n"
     ]
    }
   ],
   "source": [
    "# cleaning the data\n",
    "text_list = []\n",
    "\n",
    "# iterating through all the text\n",
    "for sent in X:         \n",
    "    sent = re.sub(r'[!@#$(),n\"%^*?:;~`0-9]', ' ',str(sent)) # removes all the symbols and numbers\n",
    "    sent = re.sub(r'[[]]', ' ', sent)\n",
    "    sent = re.sub(\"[إأٱآا]\", \"ا\", sent)\n",
    "    sent = re.sub(\"ة\", \"ه\", sent)\n",
    "    sent = sent.replace('وو', 'و')\n",
    "    sent = sent.replace('يي', 'ي')\n",
    "    sent = sent.replace('هه','')\n",
    "    sent = sent.lower()# converts all the text to lower case\n",
    "    text_list.append(sent)       # appends the text to the text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer() \n",
    "X = cv.fit_transform(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "x_train_ng = ng_vectorizer.fit_transform(x_train)\n",
    "x_test_ng = ng_vectorizer.transform(x_test)#0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ng_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "#x_train_ng = ng_vectorizer.fit_transform(x_train)\n",
    "#x_test_ng = ng_vectorizer.transform(x_test)#0.60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ng_vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "#x_train_ng = ng_vectorizer.fit_transform(x_train)\n",
    "#x_test_ng = ng_vectorizer.transform(x_test)#0.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier on the test set is 0.617\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_ng = MultinomialNB()\n",
    "\n",
    "# Fit the classifier\n",
    "clf_ng.fit(x_train_ng, y_train)\n",
    "\n",
    "# Measure the accuracy\n",
    "accuracy = clf_ng.score(x_test_ng, y_test)\n",
    "print(\"The accuracy of the classifier on the test set is %.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language is in ['BEI']\n"
     ]
    }
   ],
   "source": [
    "def predict(txt):\n",
    "    \n",
    "    texte = ng_vectorizer.transform([txt]).toarray() # convert text to bag of words model (Vector)\n",
    "    lang = clf_ng.predict(texte) # predict the language\n",
    "    lang = le.inverse_transform(lang) # find the language corresponding with the predicted value\n",
    "    print (\"The language is in\", lang) # printing the language\n",
    "predict('شو بدك انتي  ')# Call the function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language is in ['BEI']\n"
     ]
    }
   ],
   "source": [
    "def predict(txt):\n",
    "    \n",
    "    texte = ng_vectorizer.transform([txt]).toarray() # convert text to bag of words model (Vector)\n",
    "    lang = clf_ng.predict(texte) # predict the language\n",
    "    lang = le.inverse_transform(lang) # find the language corresponding with the predicted value\n",
    "    print (\"The language is in\", lang) # printing the language\n",
    "predict('شو بدك انتي  ')# Call the function    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
